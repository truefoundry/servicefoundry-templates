kind: template
metadata:
  description: A basic template for using FastAPI framework
spec:
  parameters:
    - id: service_name
      kind: string
      prompt: Name your FastAPI service
      default: my-fapi-skt-mlf-service
    - id: run_fqn
      kind: string
      prompt: FQN of you mlfoundry run
    - id: python_version
      kind: options
      prompt: Choose a Python version for your FastAPI service
      options: [ 'python:3.7', 'python:3.8', 'python:3.9' ]
      default: python3.7
    - id: workspace
      kind: tfy-workspace
      prompt: Choose a workspace to deploy your service
    - id: replicas
      kind: number
      prompt: Choose a number of replicas for your service
      default: 1
    - id: port
      kind: number
      prompt: Choose a port to run your service
      default: 8080
  postInitInstruction: |
    FastAPI service `{parameters.service_name}` is initialized.
    The service will be deployed in `{parameters.workspace}` workspace.

    Project folder `{parameters.service_name}` is created under current directory.
    Under project folder,
    1. You can find the project entrypoint `main.py`.
    2. Requirments should be defined in `requirements.txt`.

    Getting started with FastAPI? Visit the link below for first steps.
    https://fastapi.tiangolo.com/tutorial/first-steps/
  baseBuild: base_python.yaml
  baseComponent: base_service.yaml
  overwrites:
    BuildPack.spec.preBuildScript: |
      #!/bin/sh
      set -x
      mlfoundry --version
      status=$?
      [ $status -eq 0 ] && echo "mlfoundry cli is already installed" || pip install mlfoundry
      set -e
      export MLF_API_KEY=MTBlYTI5MTctZDZmMC00NmNjLWI0ZmItY2NiNTk1ZDExNzlmOmQ5NDE2MA==
      if [[ -d "model" && $(< model/.run.txt) == "${parameters.run_fqn}" ]]
      then
        echo "Model of mlfoundry run fqn ${parameters.run_fqn} is already downloaded"
      else
        rm -rf model
        echo "Going to download model of mlfoundry run fqn ${parameters.run_fqn}"
        mlfoundry download model --run_fqn ${parameters.run_fqn} --path model
        echo "${parameters.run_fqn}" > model/.run.txt
      fi
    BuildPack.spec.docker.dockerFileContent: |
      # This file is generated from service foundry. Don't make changes directly.
      FROM ${parameters.python_version}
      COPY . ./app
      COPY ./requirements.txt ./requirements.txt
      COPY ./model/requirements.txt ./model_requirements.txt
      RUN pip install -r ./requirements.txt -r ./model_requirements.txt
      WORKDIR app
      ENTRYPOINT uvicorn main:app --host 0.0.0.0 --port ${parameters.port}
    BuildPack.spec.local.requirementFiles: ["requirements.txt", "model/requirements.txt"]
    BuildPack.spec.local.runCommand: uvicorn main:app --host 127.0.0.1 --port ${parameters.port}
    Component.spec.workspace: ${parameters.workspace}
    Component.spec.name: ${parameters.service_name}
    Component.spec.traits.scale.replicas: ${parameters.replicas}
    Component.spec.container.ports:
      - containerPort: ${parameters.port}
        protocol: TCP
    comments: |
#  To customize the docker file:
#  BuildPack.spec.docker.dockerFileContent: |
#    # This file is generated from service foundry. Don't make changes directly.
#    FROM ${parameters.python_version}
#    COPY . ./app
#    COPY ./requirements.txt ./requirements.txt
#    RUN pip install -r ./requirements.txt
#    WORKDIR ap
#    ENTRYPOINT streamlit run streamlit.py --server.address 0.0.0.0 --server.port ${parameters.port}

#  To change the run command when you run the service locally
#  BuildPack.spec.localRunCommand: streamlit run streamlit.py --server.address 127.0.0.1 --server.port ${parameters.port}

#  To change the required cpu
#  Component.spec.container.resources.cpu.required: 0.5

#  To change the maximum cpu
#  Component.spec.container.resources.cpu.limit: 0.5

#  To change the required memory
#  Component.spec.container.resources.memory.required: 512000

#  To change the maximum memory
#  Component.spec.container.resources.memory.limit: 512000000

#  To change the number of replica
#  Component.spec.traits.scale.replicas: "${parameters.replicas}"

#  To change the port which are open from container
#  Component.spec.container.ports:
#    - containerPort: ${parameters.port}
#      protocol: TCP
